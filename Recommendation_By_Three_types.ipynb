{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # Load and manipulate data, provides data structure in form of data\n",
    "import numpy as np   # \n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "#Used for KNN algorithum, various ml algo are part of it\n",
    "from scipy.spatial.distance import correlation\n",
    "\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "#cal distance between two points or a major pairs of points\n",
    "from contextlib import contextmanager\n",
    "#For resource management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlibinline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading CSV files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Books data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "books = pd.read_csv('BX-Books.csv', sep = ';',error_bad_lines=False)\n",
    "books.columns=[\"ISBN\",\"title\",\"author\",\"yearOfPublication\",\"publisher\",\"imgUrls\",\"imgLm\",\"imgurlLm\"]\n",
    "books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Books Rating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('BX-Book-Ratings.csv', sep = ';',error_bad_lines=False)\n",
    "ratings.columns=[\"userID\",\"ISBN\",\"Rating\"]\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. USER's CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_csv('BX-Users.csv', sep = ';',error_bad_lines=False)\n",
    "users.columns=['userID','Location','Age']\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  1. Books data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(books.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth',-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.yearOfPublication.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that \n",
    "                    1. DK Publishing Inc and Gallimard has come in the place of year\n",
    "                    2. some year are 0 \n",
    "                    3. Few year values are not valid i.e.2037"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location where year Of publication is DK Publishing Inc\n",
    "books.loc[books.yearOfPublication == 'DK Publishing Inc',:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.loc[books.ISBN == '078946697X','yearOfPublication']= 2000\n",
    "books.loc[books.ISBN == '078946697X','bookAuthor'] = \"JMichale Teitelbum\"\n",
    "books.loc[books.ISBN == '078946697X','publisher'] = \"Dk Publishing Inc\"\n",
    "books.loc[books.ISBN == '078946697X','bookTitle'] = \"DK Readers: Creating the X-Men, How It All Began (Level 4: Proficient Readers)\\\";Michael Teitelbaum\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.loc[books.ISBN == '0789466953','yearOfPublication']= 2000\n",
    "books.loc[books.ISBN == '0789466953','bookAuthor'] = \"James Buckley\"\n",
    "books.loc[books.ISBN == '0789466953','publisher'] = \"Dk Publishing Inc\"\n",
    "books.loc[books.ISBN == '0789466953','bookTitle'] = \"DK Readers: Creating the X-Men, How Comic Books Come to Life (Level 4: Proficient Readers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.loc[books.yearOfPublication == 'Gallimard',:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.loc[books.ISBN == '2070426769','yearOfPublication']= 2003\n",
    "books.loc[books.ISBN == '2070426769','bookAuthor'] = \"Jean-Marie Gustave Le ClÃƒ?Ã‚Â©zio\"\n",
    "books.loc[books.ISBN == '2070426769','publisher'] = \"Gallimard\"\n",
    "books.loc[books.ISBN == '2070426769','bookTitle'] = \"Peuple du ciel, suivi de 'Les Bergers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set invalid parsing to NaN\n",
    "books.yearOfPublication = pd.to_numeric(books.yearOfPublication,errors = 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(books['yearOfPublication'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Means value of YOP\n",
    "books.yearOfPublication.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set YOP >2006 and 0 replace it with mean value\n",
    "# 1. First get the value and replace it with NaN\n",
    "# 2. Set NaN value with mean of YOP\n",
    "\n",
    "books.loc[(books.yearOfPublication > 2006) | (books.yearOfPublication == 0), 'yearOfPublication']  = np.NaN\n",
    "books.yearOfPublication.fillna(round(books.yearOfPublication.mean()), inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.yearOfPublication = books.yearOfPublication.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find books info which does not have any publisher name\n",
    "books.loc[books.publisher.isnull(),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace that publisher name with Other\n",
    "books.loc[(books.ISBN == '193169656X'),'publisher'] = 'other'\n",
    "books.loc[(books.ISBN == '1931696993'),'publisher'] = 'other'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Users data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Users data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.userID.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetching unique user age from users data\n",
    "print(sorted(users.Age.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that some users-age is in range 0-5 AND 90-244 which is not practically possible\n",
    "\n",
    "As well as converting the dtype is float64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.Age.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Let's Convert age value >90 and <5 with NaN\n",
    "# 2. then replace it with mean of overall age\n",
    "# 3. Now we will change the dtype with integer\n",
    "\n",
    "users.loc[(users.Age>90)|(users.Age<5),'Age'] = np.nan\n",
    "users.Age = users.Age.fillna(users.Age.mean())\n",
    "users.Age = users.Age.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's check the refined data\n",
    "print(sorted(users.Age.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Rating data Pre- processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identifies the size and column details\n",
    "print(ratings.shape)\n",
    "print(list(ratings.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No null value is present\n",
    "ratings.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rating distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc(\"font\",size=15)\n",
    "ratings.Rating.value_counts(sort = False).plot(kind = 'bar')\n",
    "plt.title(\"Rating Sitribution\")\n",
    "plt.xlabel(\"Rating\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> WE can observe that the rating is from 0-10 \n",
    "\n",
    "--> The rating for 0 is heigher  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Here 0 --> Row 1-->column '''\n",
    "n_users = users.shape[0] #get the number of rows of users data\n",
    "n_books = books.shape[0] #get the number of rows of books data\n",
    "print(n_users)\n",
    "print(n_books)\n",
    "print(n_users*n_books) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' comparing the ratings and books  data set with the help of ISBN\n",
    " If the ISBN value is same then put the book into new_retings dataset '''\n",
    "\n",
    "new_ratings = ratings[ratings.ISBN.isin(books.ISBN)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' In new_rating further filter with new_ratings and users data with the help of usersID\n",
    "    If the userID of both dataSet will match then put it into new_ratings'''\n",
    "\n",
    "new_ratings = new_ratings[new_ratings.userID.isin(users.userID)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ratings.shape) # Already existing ratings data\n",
    "print(new_ratings.shape)  # newly formed data with the help of comparison  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ratings.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ratings.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' sparsity can be achieve by from the users in greater rate only a limited number of items\n",
    " It is used in scenario of collabrative filtering'''\n",
    "\n",
    "sparsity = 1.0 -len(new_ratings)/float(n_users * n_books)\n",
    "# print(sparsity)\n",
    "print(\"The sparsity level of book crossing is \" + str(sparsity *100)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.Rating.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide ratings into two parts \n",
    "# 1. rating without 0\n",
    "# 2. rating with 0\n",
    "\n",
    "rating_explict = new_ratings[new_ratings.Rating!= 0]\n",
    "rating_implict = new_ratings[new_ratings.Rating == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identifying the users who are not given zero rating\n",
    "user_exp_ratings = users[users.userID.isin(rating_explict.userID)]\n",
    "\n",
    "# identifying the users who are not given zero rating\n",
    "user_imp_ratings = users[users.userID.isin(rating_implict.userID)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking shape\n",
    "print(new_ratings.shape)\n",
    "print(rating_explict.shape)\n",
    "print(rating_implict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data =rating_explict,x='Rating' )\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Popularity Based Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Taking the each book by grouping with the help of their ISBN. sum all the rating given by different users and arrange it in \n",
    "     descending order so that those top most books can be recommended to any of the users '''\n",
    "\n",
    "ratings_count = pd.DataFrame(rating_explict.groupby(['ISBN'])['Rating'].sum())\n",
    "top7 = ratings_count.sort_values('Rating', ascending = False).head(7)\n",
    "\n",
    "print(\"Following are the top rated books\")\n",
    "top7.merge(books, left_index = True ,right_on = 'ISBN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collborative filtering based Recommendation Syatem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Let's find the count of unique userID '''\n",
    "\n",
    "count1 = rating_explict['userID'].value_counts();\n",
    "#print(count1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Let's  Keept the record of users who's buying count is more than 100 i.e. which are more frequent users''' \n",
    "''' and store  the result into rating_explict '''\n",
    "\n",
    "rating_explict = rating_explict[rating_explict['userID'].isin(count1[count1 >=100].index)]\n",
    "#print(rating_explict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' finding the count of unique book rating'''\n",
    "count = rating_explict['Rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' here we are keeping the details in rating_exp by considering count of book rating with greater than or equal to 100\n",
    "    of the frequent users which indicates that the frequent user ratings are being consiered for the recommendation '''\n",
    "\n",
    "rating_explict = rating_explict[rating_explict['Rating'].isin(count[count >=100].index)]\n",
    "print(rating_explict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Rating matrix generation'''\n",
    "ratingMatrix = rating_explict.pivot(index='userID',columns = 'ISBN',values = 'Rating')\n",
    "userID =ratingMatrix.index\n",
    "ISBN = ratingMatrix.columns\n",
    "\n",
    "print(ratingMatrix.shape)\n",
    "ratingMatrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Replace NaN val with 0'''\n",
    "ratingMatrix.fillna(0,inplace = True)\n",
    "ratingMatrix = ratingMatrix.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingMatrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global metric,k\n",
    "k=10\n",
    "metric ='cosine'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Collebrative filtering using KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## in order to find out which books are popular, we need to combine book data with rating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = pd.read_csv(\"BX-Books.csv\",sep=';',error_bad_lines = False)\n",
    "books.columns=[\"ISBN\",\"title\",\"author\",\"yearOfPublication\",\"publisher\",\"imgUrls\",\"imgLm\",\"imgurlLm\"]\n",
    "\n",
    "users = pd.read_csv('BX-Users.csv', sep = ';',error_bad_lines=False)\n",
    "users.columns=['userID','Location','Age']\n",
    "\n",
    "ratings = pd.read_csv('BX-Book-Ratings.csv', sep = ';',error_bad_lines=False)\n",
    "ratings.columns=[\"userID\",\"ISBN\",\"Rating\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_book_rating = pd.merge(ratings,books,on='ISBN')\n",
    "columns = [\"author\",\"yearOfPublication\",\"publisher\",\"imgUrls\",\"imgLm\",\"imgurlLm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_book_rating = combine_book_rating.drop(columns,axis=1)\n",
    "combine_book_rating.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group by book titles and create new column for total rating count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_book_rating = combine_book_rating.dropna(axis =0,subset=['title'])\n",
    "#drop NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_ratingCount = (combine_book_rating.groupby(by=['title'])['Rating'].count().reset_index()\n",
    "                   .rename(columns = {'Rating':'TotRatingCount'})[['title','TotRatingCount']])\n",
    "#group by title considering rating columns count\n",
    "#reset the index as we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_ratingCount.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_with_totalratingCount = combine_book_rating.merge(book_ratingCount, left_on = 'title', right_on = 'title', how= 'inner')\n",
    "#left_on indicates column or index names to join the left dataframe\n",
    "#right_on indicates column or index level names to join on in the right dataframe\n",
    "#how indicates type of merge(joins) to be performed as if in SQL.values are left right and inner\n",
    "\n",
    "rating_with_totalratingCount.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format',lambda x:'%.3f'%x)\n",
    "print(book_ratingCount['TotRatingCount'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The median book has been rated only once. Let's look at the top of the distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(book_ratingCount['TotRatingCount'].quantile(np.arange(.9,1,.01)))\n",
    "#it is to consider the range of top 10% with difference of 1%. i.e from 90% to 100% identfy the total rating count for each\n",
    "#of the quantile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About 1% of the books received 50 or more ratings. Because we have so many books in our data.\n",
    "we will limit it to the top 1% and this will guve us 7085 unique books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#popularity_threshold = 50\n",
    "rating_popular_book = rating_with_totalratingCount.query('TotRatingCount >= 50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rating_with_totalratingCount.shape)\n",
    "rating_with_totalratingCount.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rating_popular_book.shape)\n",
    "rating_popular_book.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_popular_book['ISBN'].nunique()#It gives the information of unique books are there with respect to ISBN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter to users in US and Canada Only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order  to improve computing speed and not eun into the \"MemoryError\" issue, we will limit our user data to those in the US and canda and the user dataandtotal rating count data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = rating_popular_book.merge(users, left_on = 'userID', right_on = 'userID', how ='left')\n",
    "#here combine data is been generated by using the principle of joins as in DataSet concepts \n",
    "#Join between rating_popular_book and user by using left join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usCandaUserRating = combined[combined['Location'].str.contains(\"usa|canada\")]\n",
    "usCandaUserRating = usCandaUserRating.drop(\"Age\",axis = 1)\n",
    "usCandaUserRating.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not usCandaUserRating[usCandaUserRating.duplicated(['userID','title'])].empty:\n",
    "    initial_rows = usCandaUserRating.shape[0] #identify the no. of rows corresponding to countries US and Canada\n",
    "    print('Initial dataframe shape {0}'.format(usCandaUserRating.shape))\n",
    "    \n",
    "    usCandaUserRating = usCandaUserRating.drop_duplicates(['userID','title'])\n",
    "    current_rows = usCandaUserRating.shape[0]#identifying the no of rows corresponding to us and canada userswithout duplicates\n",
    "    \n",
    "    print('New dataframe shape {0}'.format(usCandaUserRating.shape))\n",
    "    print('Removed {0} rows'.format(initial_rows - current_rows ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usCandaUserRating_pivot = usCandaUserRating.pivot(index ='title',columns='userID',values='Rating').fillna(0)\n",
    "usCandaUserRating_matrix = csr_matrix(usCandaUserRating_pivot.values)\n",
    "#create pivot table and convert the values into matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding nearest neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_knn = NearestNeighbors(metric ='cosine',algorithm = 'brute')\n",
    "model_knn.fit(usCandaUserRating_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test our model and make recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_index = np.random.choice(usCandaUserRating_pivot.shape[0])\n",
    "distances,indices =model_knn.kneighbors(usCandaUserRating_pivot.iloc[query_index,:].values.reshape(1,-1),n_neighbors=6)\n",
    "for i in range(0,len(distance.flatten())):\n",
    "    if i ==0:\n",
    "         print(\"Recommendations for {0}: \\n\" .format(usCandaUserRating_pivot.index[query_index]))\n",
    "    else:\n",
    "        print(\"{0}:{1}, with distance of {2}:\".format(i,usCandaUserRating_pivot.index[indices.flatten()[i]],distances.flatten()[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usCandaUserRating_pivot2 =usCandaUserRating.pivot(index='userID',columns='title',values='Rating').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usCandaUserRating_pivot2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usCandaUserRating_pivot2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = usCandaUserRating_pivot2.values.T\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.decomposition import TruncatesSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
